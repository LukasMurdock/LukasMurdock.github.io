---
layout: post
title: 'Typical Mind Fallacy'
description: "I’ve begun to see a common error in myself."
date: October 29, 2020
last_modified_at: 2020-10-29T04:26:18+0000
---


In conversations I often assume others have the same shared understanding that I have. That the things that I know, everyone knows, and their thinking utilizes the same working knowledge.

I continuously deny acknowledging my learning or expertise.

## The conceivability of being wrong
The idea that I was doing was first made aware to be in Seth Godin’s post [The only one who has heard all of it](https://seths.blog/2020/01/the-only-one-who-has-heard-all-of-it/). You’re the only one who has heard all of it.

> Tell us what we need to know. Not because you need to hear yourself repeat it, but because you believe we need to hear it.
> 
> Take your time and lay it out for us, without worrying about whether or not we’ve heard you say it before. We probably haven’t.

I added that post to my [around the web](https://lukasmurdock.com/aroundtheweb/) resources back in February 2020.

I first added the site [LessWrong](https://www.lesswrong.com/) to my [knowledge resources](https://lukasmurdock.com/knowledge/) page on July 9, 2020.

LessWrong is a community blog devoted to the art of human rationality.

I took AP Psychology in my third year of high school. The required reading for the class was [Blink by Malcolm Gladwell](https://lukasmurdock.com/booklist/). You may notice that is the first book on my booklist. Before the class had even begun, that book opened my eyes to ideas that challenged the intuitive assumptions we all simply assume and move on about.

The book and class introduced me to an entirely new field of thinking. I no longer remember what it was like to not know what I know about the human condition. We hold ourselves to be great and mighty, and deny our feebleness and erroneousness. Our minds were designed eons ago to believe convenient delusions that helped our survivability, not to be accurate. Yet we find ourselves deluded with the idea of being right under false pretenses.

This has led me to “shut up and sit down” not from the demands of compliance from the educational system but from the fact that there is too much I do not know. It is very hard to be confident in oneself when you are aware of a plethora of ways in which humans commonly fool themselves.

> But this long history of learning how to not fool ourselves—of having utter scientific integrity—is, I’m sorry to say, something that we haven’t specifically included in any particular course that I know of. We just hope you’ve caught on by osmosis.\
> The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that. After you’ve not fooled yourself, it’s easy not to fool other scientists. You just have to be honest in a conventional way after that.

In my last year of high school, I read *[Surely You're Joking, Mr. Feynman](https://lukasmurdock.com/booklist/)*. The book was released in 1985 and covers various parts of the life of Richard Feynman. Feynman was an American theoretical physicist, known for his work [in science](https://en.wikipedia.org/wiki/Richard_Feynman) and received the Nobel Prize in Physics in 1965.

In 1974, Feynman delivered a Caltech commencement address on the topic of [cargo cult science](http://calteches.library.caltech.edu/51/2/CargoCult.htm). Cargo cult science has the semblance of science, but is pseudoscience from its lack of scientific integrity, a principle of scientific thought that corresponds to utter honesty on the part of the scientist. He instructed the graduating class that you must not fool yourself—and you are the easiest person to fool.

As Feynman said, this learning how to not fool ourselves is not part of any particular course. I would love to see a book or film focusing on the idea “the ways we thought we were right.” 

This is where I find value in the saying “those who do not learn history are doomed to repeat it.” History, in part, holds true many ways we thought we were right yet proved to be wrong in various ways. I imagine that through looking at history, the idea that we often think we are right when we are wrong is undeniable.

But that hardest part in anything is gaining enrollment—a willingness to engage and move forward.

## Being wrong feels just like being right

Through *[The Great Mental Models](https://lukasmurdock.com/booklist/)* by Farnam Street, I learned the idea of “the map is not the territory.” 

> The map of reality is not reality. Even the best maps are imperfect. That’s because they are reductions of what they represent. If a map were to represent the territory with perfect fidelity, it would no longer be a reduction and thus would no longer be useful to us. A map can also be a snapshot of a point in time, representing something that no longer exists. This is important to keep in mind as we think through problems and make better decisions.

And from my newly found favorite online place, [LessWrong](https://www.lesswrong.com/tag/the-map-is-not-the-territory):

> The map is not the territory metaphorically illustrates the differences between belief and reality. The phrase was coined by Alfred Korzybski. Our perception of the world is being generated by our brain and can be considered as a 'map' of reality written in neural patterns. Reality exists outside our mind but we can construct models of this 'territory' based on what we glimpse through our senses.

What we each believe, we each feel to be right. That what we believe is the way the world is. Yet sometimes we feel that other people seem to be inhabiting a different world. Disagreements arise not because one party is stubborn, but because the world *feels* different to them.

Through these I became vaguely aware of an idea that we hold mistaken views of others by projecting ourselves.

And in exploring LessWrong, I came across “typical mind fallacy” in the post *[Generalizing From One Example](https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example)* by Scott Alexander in 2009:

> the Typical Mind Fallacy: the human tendency to believe that one's own mental structure can be generalized to apply to everyone else's.\
> …\
> We only have direct first-person knowledge one one mind, one psyche, and one social circle, and we find it tempting to treat it as typical even in the face of contrary evidence.

And from the LessWrong wiki page on [Typical Mind Fallacy](https://www.lesswrong.com/tag/typical-mind-fallacy):
> The typical mind fallacy is the mistake of modeling the minds inside other people's brains as exactly the same as your own mind. Humans lack insight into their own minds and what is common among everyone or unusually specific to a few. It can be often hard to see the flaws in the lens, especially when we only have one lens to look through with which to see those flaws.

This is a large cause of biased and overconfident conclusions of other people’s experiences based on your own personal experience.

I have been subjecting myself to thinking that other people have the same or similar mental structure that I have formed.

In 2020, I have rarely found myself in new conversations. However, through the few conversations I’ve had with people I have come up with a few interesting questions that I absolutely love asking. These questions aim to enlighten me from my typical mind fallacy in believing that everyone thinks under the same working knowledge—an argument so obvious yet I need to make it clearer to myself.

And the answers are always fascinatingly different.

- How do you show up in the world? If I were to go somewhere to learn more about you without talking to you, where would I go?
- On a day-to-day or week-to-week basis Where do you go to inform yourself? What are the specific names of people or organizations that when you come across you pay attention to what they’re saying?

